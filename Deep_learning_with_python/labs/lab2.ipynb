{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f37a4e",
   "metadata": {},
   "source": [
    "# Laboratory 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f716c",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Create two classes of random points in 2D plain. Each class should contain 1000 points from the bivariate normal distribution:\n",
    "- the first with mean $\\mu_1=[0, 1.5]$ and covariance matrix $\\Sigma_1=\\begin{bmatrix}1/3& 1/6\\\\1/6& 1/3\\end{bmatrix}$\n",
    "- the second with mean $\\mu_2=[2,0]$ and covariance matrix $\\Sigma_2=\\begin{bmatrix}2/3& 1/3\\\\1/3& 2/3\\end{bmatrix}$\n",
    "\n",
    "Next generate corresponding target labels: 0 for the first class and 1 for the second class and visualize two classes:\n",
    "<img src=\"../lectures/Lecture 2-20250316/1.png\" alt=\"Two classes\"/>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "num_points = 1000\n",
    "mean1 = [0, 1.5]\n",
    "cov1 = [[1/3, 1/6], [1/6, 1/3]]\n",
    "mean2 = [2, 0]\n",
    "cov2 = [[2/3, 1/3], [1/3, 2/3]]\n",
    "points1 = np.random.multivariate_normal(mean1, cov1, num_points)\n",
    "points2 = np.random.multivariate_normal(mean2, cov2, num_points)\n",
    "targets1 = np.zeros(num_points)\n",
    "targets2 = np.ones(num_points)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(points1[:, 0], points1[:, 1], color='blue')\n",
    "plt.scatter(points2[:, 0], points2[:, 1], color='yellow')\n",
    "plt.show()"
   ],
   "id": "b2cc5283bb68c7b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ff718443",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Create the linear classifier of the form $prediction = W \\cdot input + b$, where $W$ is tensorflow variable with initial value being random uniform vector of shape (2,1) and $b$ is tensorflow variable with initial value equal 0. Using tensor operations define the forward pass function returning for input: $W \\cdot input + b$."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable(tf.random.uniform(shape=(2, 1), minval=-0.1, maxval=0.1), dtype=tf.float32)\n",
    "b = tf.Variable(0.0, dtype=tf.float32)\n",
    "\n",
    "def forward(inputs):\n",
    "    return tf.matmul(inputs, W) + b"
   ],
   "id": "8539d424ba87e416",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5da7bace",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "For input: targets and predictions, define the mean squared error loss function using tensor operations."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def loss(targets, predictions):\n",
    "    return tf.reduce_mean(tf.square(targets - predictions))"
   ],
   "id": "7afac3f2f78fb810",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ddaae7ce",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "For learning rate 0.1 define the training step function. The function for arguments: inputs, targets, should:\n",
    "- do forward pass, inside a gradient tape scope\n",
    "- retrieve the gradient of the loss with regard to weights \n",
    "- update the weights\n",
    "- return loss"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = forward(inputs)\n",
    "        current_loss = loss(targets, predictions)\n",
    "    gradients = tape.gradient(current_loss, [W, b])\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "\n",
    "    return current_loss"
   ],
   "id": "d559c03d2257f5ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c7871e38",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "Perform the training step function 50 times."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Połączenie danych i etykiet\n",
    "inputs = np.vstack((points1, points2)).astype(np.float32)\n",
    "targets = np.hstack((np.zeros(1000), np.ones(1000))).astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# Konwersja na tensory TensorFlow\n",
    "inputs = tf.convert_to_tensor(inputs)\n",
    "targets = tf.convert_to_tensor(targets)\n",
    "\n",
    "for i in range(50):\n",
    "    current_loss = train_step(inputs, targets)\n",
    "    print(f\"Loss at step {i}: {current_loss.numpy()}\")\n",
    "\n"
   ],
   "id": "f0e06c09d315292f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "150f8ed8",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "Do predictions for the model: a given input point will be classified as “0” if its prediction value is below 0.5, and as “1” if it is above 0.5. Visualize model predictions:\n",
    "<img src=\"../lectures/Lecture 2-20250316/2.png\" alt=\"Model predictions\"/>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Predykcja dla danych testowych\n",
    "predictions = forward(inputs).numpy()  # Forward pass\n",
    "predicted_classes = (predictions > 0.5).astype(int)  # Klasyfikacja (0 lub 1)\n",
    "\n",
    "# Wizualizacja predykcji w stylu \"plt.scatter\"\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Rysowanie klasy 0 (fioletowy)\n",
    "points1 = inputs.numpy()[predicted_classes.flatten() == 0]\n",
    "plt.scatter(points1[:, 0], points1[:, 1], color='blue')\n",
    "\n",
    "# Rysowanie klasy 1 (żółty)\n",
    "points2 = inputs.numpy()[predicted_classes.flatten() == 1]\n",
    "plt.scatter(points2[:, 0], points2[:, 1], color='yellow')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# second class\n",
    "plt.show()"
   ],
   "id": "9e182fba24d340c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "50cd0072",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "Add to the above plot  a classifying line in the 2D plane\n",
    "$$y = -\\frac{w_1}{w_2}x + \\frac{0.5-b}{w_2}$$ \n",
    "<img src=\"../lectures/Lecture 2-20250316/3.png\" alt=\"Classifying lines with predicted targets\"/>\n",
    "Next add the classifying line to plot of samples with original targets\n",
    "<img src=\"../lectures/Lecture 2-20250316/4.png\" alt=\"Classifying lines with original targets\"/>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "w1, w2 = W.numpy().reshape(-1)\n",
    "b = b.numpy()\n",
    "x = np.linspace(-2, 4, 100)\n",
    "y = -w1/w2*x + (0.5-b)/w2\n",
    "# Wizualizacja predykcji w stylu \"plt.scatter\"\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Rysowanie klasy 0 (fioletowy)\n",
    "points1 = inputs.numpy()[predicted_classes.flatten() == 0]\n",
    "plt.scatter(points1[:, 0], points1[:, 1], color='blue')\n",
    "\n",
    "# Rysowanie klasy 1 (żółty)\n",
    "points2 = inputs.numpy()[predicted_classes.flatten() == 1]\n",
    "plt.scatter(points2[:, 0], points2[:, 1], color='yellow')\n",
    "\n",
    "plt.plot(x, y, color='black')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Rysowanie klasy 0 (fioletowy) - dla oryginalnych etykiet\n",
    "points1 = inputs.numpy()[targets.numpy().flatten() == 0]\n",
    "plt.scatter(points1[:, 0], points1[:, 1], color='blue')\n",
    "\n",
    "# Rysowanie klasy 1 (żółty) - dla oryginalnych etykiet\n",
    "points2 = inputs.numpy()[targets.numpy().flatten() == 1]\n",
    "plt.scatter(points2[:, 0], points2[:, 1], color='yellow')\n",
    "plt.plot(x, y, color='black')\n",
    "plt.show()\n"
   ],
   "id": "1b2e7133afb4884d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "96eb7b76",
   "metadata": {},
   "source": [
    "## Taks 8\n",
    "Create 3 keras sequential models having the last layer with 1 unit and the sigmoid activation function. The second and third model are to have 2 layers with the first layer having the relu activation function and 2, 10 units, respectively. To compile all three models use the rmsprop optimizer, the binary_crossentropy loss function, and the accuracy metric. Fit all models using:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c64704",
   "metadata": {},
   "source": [
    "```python\n",
    "training_inputs,\n",
    "training_targets,\n",
    "epochs=50,\n",
    "batch_size=16,\n",
    "validation_data=(val_inputs, val_targets)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e2bd0",
   "metadata": {},
   "source": [
    "where `inputs` and `targets` are from Task 1 and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f27d4",
   "metadata": {},
   "source": [
    "```python\n",
    "indices_permutation = np.random.permutation(len(inputs))\n",
    "shuffled_inputs = inputs[indices_permutation]\n",
    "shuffled_targets = targets[indices_permutation]\n",
    "\n",
    "num_validation_samples = int(0.3 * len(inputs))\n",
    "val_inputs = shuffled_inputs[:num_validation_samples]\n",
    "val_targets = shuffled_targets[:num_validation_samples]\n",
    "training_inputs = shuffled_inputs[num_validation_samples:]\n",
    "training_targets = shuffled_targets[num_validation_samples:]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb293ac8",
   "metadata": {},
   "source": [
    "Evaluate all models for `val_inputs`, `val_targets`, `batch_size=16`. Which model has the smallest loss? Do predictions for all models with `val_inputs` and `batch_size=16`. Finally visualize `val_inputs` with original targets and targets predicted by all three models. \n",
    "<img src=\"../lectures/Lecture 2-20250316/5.png\" alt=\"Original data and predictions\"/>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "indices_permutation = np.random.permutation(len(inputs))\n",
    "indices_permutation = tf.convert_to_tensor(indices_permutation, dtype=tf.int32)\n",
    "\n",
    "shuffled_inputs = tf.gather(inputs, indices_permutation)\n",
    "shuffled_targets = tf.gather(targets, indices_permutation)\n",
    "\n",
    "num_validation_samples = int(0.3 * len(inputs))\n",
    "val_inputs = shuffled_inputs[:num_validation_samples]\n",
    "val_targets = shuffled_targets[:num_validation_samples]\n",
    "training_inputs = shuffled_inputs[num_validation_samples:]\n",
    "training_targets = shuffled_targets[num_validation_samples:]\n",
    "\n",
    "model1 = keras.Sequential([\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model1.compile(optimizer='rmsprop',\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "model1.fit(training_inputs, training_targets, epochs=50, batch_size=16, validation_data=(val_inputs, val_targets))\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    layers.Dense(2, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model2.compile(optimizer='rmsprop',\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "model2.fit(training_inputs, training_targets, epochs=50, batch_size=16, validation_data=(val_inputs, val_targets))\n",
    "\n",
    "model3 = keras.Sequential([\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model3.compile(optimizer='rmsprop',\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "model3.fit(training_inputs, training_targets, epochs=50, batch_size=16, validation_data=(val_inputs, val_targets))\n",
    "\n",
    "model1_loss = model1.evaluate(val_inputs, val_targets, batch_size=16)\n",
    "model2_loss = model2.evaluate(val_inputs, val_targets, batch_size=16)\n",
    "model3_loss = model3.evaluate(val_inputs, val_targets, batch_size=16)\n",
    "print(f\"Model 1 loss: {model1_loss}\")\n",
    "print(f\"Model 2 loss: {model2_loss}\")\n",
    "print(f\"Model 3 loss: {model3_loss}\")\n",
    "\n",
    "predictions1 = model1.predict(val_inputs, batch_size=16)\n",
    "predictions2 = model2.predict(val_inputs, batch_size=16)\n",
    "predictions3 = model3.predict(val_inputs, batch_size=16)\n",
    "\n",
    "predicted_classes1 = (predictions1 > 0.5).astype(int)\n",
    "predicted_classes2 = (predictions2 > 0.5).astype(int)\n",
    "predicted_classes3 = (predictions3 > 0.5).astype(int)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Model 1 Predictions\")\n",
    "points1 = val_inputs.numpy()[predicted_classes1.flatten() == 0]\n",
    "points2 = val_inputs.numpy()[predicted_classes1.flatten() == 1]\n",
    "plt.scatter(points1[:, 0], points1[:, 1], color='blue')\n",
    "plt.scatter(points2[:, 0], points2[:, 1], color='yellow')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Model 2 Predictions\")\n",
    "points1 = val_inputs.numpy()[predicted_classes2.flatten() == 0]\n",
    "points2 = val_inputs.numpy()[predicted_classes2.flatten() == 1]\n",
    "plt.scatter(points1[:, 0], points1[:, 1], color='blue')\n",
    "plt.scatter(points2[:, 0], points2[:, 1], color='yellow')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Model 3 Predictions\")\n",
    "points1 = val_inputs.numpy()[predicted_classes3.flatten() == 0]\n",
    "points2 = val_inputs.numpy()[predicted_classes3.flatten() == 1]\n",
    "plt.scatter(points1[:, 0], points1[:, 1], color='blue')\n",
    "plt.scatter(points2[:, 0], points2[:, 1], color='yellow')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Original Data\")\n",
    "points1 = val_inputs.numpy()[val_targets.numpy().flatten() == 0]\n",
    "points2 = val_inputs.numpy()[val_targets.numpy().flatten() == 1]\n",
    "plt.scatter(points1[:, 0], points1[:, 1], color='blue')\n",
    "plt.scatter(points2[:, 0], points2[:, 1], color='yellow')\n",
    "\n",
    "plt.show()"
   ],
   "id": "20c20c11b09cb93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "70bde29b67d8c9df",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
